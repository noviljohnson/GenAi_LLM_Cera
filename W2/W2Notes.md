## Week 2 Notes

### Fine Tuning an LLM with Instruction Prompts

=> In context Learning (ICL) - Zero Shot Inference 
    - Some LLMs performs zero shot infence well with simple prompt.
    - some small language models perform well few shot inference.

  - limitation of ICL
    - ICL may not work for small LMs even with few shot
    - examples take up space in the context window
  * use fine tune
